---
title: LLM Context
sidebar_label: "LLM Context"
sidebar_position: 600
description: "Customizing the context provided to the Agent's LLM"
---

기본적으로 에이전트는 스레드의 메시지 히스토리를 기반으로 컨텍스트를 제공합니다. 이 컨텍스트는 다음 메시지를 생성하는 데 사용됩니다.

컨텍스트에는 최근 메시지와 텍스트 및/또는 벡터 검색을 통해 찾은 메시지가 포함될 수 있습니다.

`promptMessageId`가 제공되면 컨텍스트에 해당 메시지와 동일한 `order`의 다른 메시지가 포함됩니다. order에 대한 자세한 내용은 [messages.mdx](./messages.mdx#message-ordering)에 있지만, 실제로는 사용자가 제출한 메시지의 ID를 `promptMessageId`로 전달하고 이미 일부 어시스턴트 및/또는 툴 응답이 있었다면 해당 응답이 컨텍스트에 포함되어 LLM이 대화를 계속할 수 있습니다.

또한 [RAG](./rag.mdx)를 사용하여 프롬프트에 추가 컨텍스트를 추가할 수도 있습니다.

## 컨텍스트 커스터마이징

커스텀 `contextOptions`를 사용하여 메시지를 생성할 때 에이전트에 제공되는 컨텍스트를 커스터마이즈할 수 있습니다. 이는 `Agent`의 기본값으로 설정하거나 `generateText` 또는 기타 함수의 호출 위치에서 제공할 수 있습니다.

```ts
const result = await agent.generateText(
  ctx,
  { threadId },
  { prompt },
  {
    // 표시된 값은 기본값입니다.
    contextOptions: {
      // 컨텍스트에서 툴 메시지를 제외할지 여부
      excludeToolMessages: true,
      // 포함할 최근 메시지 수. 검색 메시지 이후에 추가되며
      // 검색 제한에 포함되지 않습니다.
      recentMessages: 100,
      // 텍스트 및/또는 벡터 검색을 통해 메시지를 검색하는 옵션
      searchOptions: {
        limit: 10, // 가져올 최대 메시지 수
        textSearch: false, // 텍스트 검색을 사용하여 메시지를 찾을지 여부
        vectorSearch: false, // 벡터 검색을 사용하여 메시지를 찾을지 여부
        // 참고, 이것은 제한이 적용된 후입니다.
        // 예를 들어 가져온 메시지 수를 4배로 늘립니다.
        // (검색에서 찾은 각 메시지 전에 2개, 후에 1개)
        messageRange: { before: 2, after: 1 },
      },
      // 관련 메시지를 위해 다른 스레드를 검색할지 여부
      // 기본적으로 현재 스레드만 검색됩니다.
      searchOtherThreads: false,
    },
  },
);
```

## 전체 컨텍스트 제어

LLM에 전달되는 메시지를 완전히 제어하려면 다음 중 하나를 수행할 수 있습니다:

1. 컨텍스트 메시지를 필터링, 수정 또는 보강하기 위해 `contextHandler`를 제공합니다.
2. `messages` 인수를 통해 모든 메시지를 수동으로 제공하고 최근 또는 검색 메시지를 사용하지 않도록 `contextOptions`를 지정합니다. 컨텍스트 메시지를 수동으로 가져오는 방법은 아래를 참조하세요.

### contextHandler 제공하기

에이전트는 검색, 최근, 입력 메시지 및 `promptMessageId`가 제공된 경우 동일한 `order`의 모든 메시지의 메시지를 결합합니다.

컨텍스트 메시지를 추가하거나 제거하여 결합 방법을 커스터마이즈할 수 있으며, LLM에 전달될 `ModelMessage[]`를 반환하는 `contextHandler`를 제공할 수 있습니다.

에이전트 생성자에서 `contextHandler`를 지정하거나 단일 생성의 호출 위치에서 지정할 수 있으며, 이는 에이전트 기본값을 재정의합니다.

```ts
const myAgent = new Agent(components.agent, {
  ///...
  contextHandler: async (ctx, args) => {
    // 이것은 기본 동작입니다.
    return [
      ...args.search,
      ...args.recent,
      ...args.inputMessages,
      ...args.inputPrompt,
      ...args.existingResponses,
    ];
    // 다음과 동일합니다:
    return args.allMessages;
  },
);
```

이 콜백을 사용하면 다음을 수행할 수 있습니다:

1. 포함하지 않으려는 메시지를 필터링합니다.
1. 메모리 또는 기타 컨텍스트를 추가합니다.
1. LLM이 응답하는 방법을 안내하는 샘플 메시지를 추가합니다.
1. 사용자 또는 스레드를 기반으로 추가 컨텍스트를 주입합니다.
1. 다른 스레드의 메시지를 복사합니다.
1. 메시지를 요약합니다.

예를 들어:

```ts
// 참고: 호출 위치에서 지정하면 범위에서 사용 가능한 변수도 활용할 수 있습니다.
// 예를 들어 사용자가 워크플로우의 특정 단계에 있는 경우
const result = await agent.generateText(
  ctx,
  { threadId },
  { prompt },
  {
    contextHandler: async (ctx, args) => {
      // 관련이 없는 메시지를 필터링합니다.
      const relevantSearch = args.search.filter((m) => messageIsRelevant(m));
      // 모든 프롬프트에 포함할 사용자 메모리를 가져옵니다.
      const userMemories = await getUserMemories(ctx, args.userId);
      // LLM이 응답하는 방법을 안내하는 샘플 메시지를 가져옵니다.
      const sampleMessages = [
        { role: "user", content: "두 숫자를 더하는 함수를 생성하세요" },
        { role: "assistant", content: "function add(a, b) { return a + b; }" },
      ];
      // 모든 프롬프트에 포함할 사용자 컨텍스트를 가져옵니다.
      const userContext = await getUserContext(ctx, args.userId, args.threadId);
      // 관련/부모 스레드에서 메시지를 가져옵니다.
      const related = await getRelatedThreadMessages(ctx, args.threadId);
      return [
        // 컨텍스트 메시지가 너무 길면 요약하거나 자릅니다.
        ...(await summarizeOrTruncateIfTooLong(related)),
        ...relevantSearch,
        ...userMemories,
        ...sampleMessages,
        ...userContext,
        ...args.recent,
        ...args.inputMessages,
        ...args.inputPrompt,
        ...args.existingResponses,
      ];
    },
  },
);
```

### 수동으로 컨텍스트 가져오기

LLM을 호출하지 않고 주어진 프롬프트에 대한 컨텍스트 메시지를 가져오려면 `fetchContextWithPrompt`를 사용할 수 있습니다. 이는 AI SDK의 `generateText`, `streamText` 등에 전달되는 컨텍스트 메시지를 가져오기 위해 내부적으로 사용됩니다.

일반 생성과 마찬가지로 `prompt` 또는 `messages`를 제공하거나 사전 저장된 메시지를 프롬프트로 사용하여 컨텍스트 메시지를 가져오기 위해 `promptMessageId`를 제공할 수 있습니다.

이는 입력 메시지와 결합된 최근 및 검색 메시지를 반환합니다.

```ts
import { fetchContextWithPrompt } from "@convex-dev/agent";

const { messages } = await fetchContextWithPrompt(ctx, components.agent, {
  prompt,
  messages,
  promptMessageId,
  userId,
  threadId,
  contextOptions,
});
```

## 메시지 검색

이것은 에이전트가 자동으로 수행하는 작업이지만 수동으로 수행하면 유용할 수 있습니다. 예를 들어 포함할 커스텀 컨텍스트를 찾는 데 유용합니다.

텍스트 및 벡터 검색의 경우 `targetMessageId` 및/또는 `searchText`를 제공할 수 있습니다. 벡터 검색을 위해 텍스트를 임베드합니다. `searchText`가 제공되지 않으면 대상 메시지의 텍스트를 사용합니다.

`targetMessageId`가 제공되면 해당 메시지 이전의 검색 메시지와 해당 메시지의 "order"까지 포함된 최근 메시지만 가져옵니다. 이를 통해 이전 메시지에 대한 응답을 재생성할 수 있습니다.

```ts
import type { MessageDoc } from "@convex-dev/agent";

const messages: MessageDoc[] = await agent.fetchContextMessages(ctx, {
  threadId,
  searchText: prompt, // 텍스트/벡터 검색을 원하지 않는 한 선택 사항
  targetMessageId: promptMessageId, // 선택적으로 검색 대상 지정
  userId, // `searchOtherThreads`가 true가 아니면 선택 사항
  contextOptions, // 선택 사항, 제공되지 않으면 기본값 사용
});
```

참고: 에이전트 없이 메시지를 검색할 수도 있습니다. 주요 차이점은 벡터 검색을 수행하려면 직접 임베딩을 생성해야 하며 사용량 핸들러가 실행되지 않는다는 것입니다.

```ts
import { fetchRecentAndSearchMessages } from "@convex-dev/agent";

const { recentMessages, searchMessages } = await fetchRecentAndSearchMessages(
  ctx,
  components.agent,
  {
    threadId,
    searchText: prompt, // 텍스트/벡터 검색을 원하지 않는 한 선택 사항
    targetMessageId: promptMessageId, // 선택적으로 검색 대상 지정
    contextOptions, // 선택 사항, 제공되지 않으면 기본값 사용
    getEmbedding: async (text) => {
      const embedding = await textEmbeddingModel.embed(text);
      return { embedding, textEmbeddingModel };
    },
  },
);
```

## 다른 스레드 검색

`searchOtherThreads`를 `true`로 설정하면 에이전트는 제공된 `userId`에 속한 모든 스레드를 검색합니다. 이는 에이전트가 참조할 수 있는 여러 대화를 갖는 데 유용할 수 있습니다.

검색은 텍스트 및 벡터 검색의 하이브리드를 사용합니다.

## 컨텍스트로 메시지 전달하기

예를 들어 [검색 증강 생성](./rag.mdx)을 구현하기 위해 에이전트의 LLM에 컨텍스트로 메시지를 전달할 수 있습니다. LLM에 전송되는 최종 메시지는 다음과 같습니다:

1. 시스템 프롬프트(제공된 경우 또는 에이전트에 `instructions`가 있는 경우)
2. contextOptions를 통해 찾은 메시지
3. `generateText` 또는 기타 함수 호출에 전달된 `messages` 인수
4. `prompt` 인수가 제공된 경우 최종 `{ role: "user", content: prompt }` 메시지

이를 통해 스레드 히스토리의 일부가 아니고 자동으로 저장되지 않지만 LLM이 컨텍스트로 받을 메시지를 전달할 수 있습니다.

## 수동으로 임베딩 관리하기

에이전트 생성자의 `textEmbeddingModel` 인수를 사용하면 벡터 검색에 사용할 텍스트 임베딩 모델을 지정할 수 있습니다.

이를 설정하면 에이전트가 메시지에 대한 임베딩을 자동으로 생성하고 벡터 검색에 사용합니다.

모델을 변경하거나 벡터 검색을 위한 임베딩 사용을 시작하거나 중지하기로 결정하면 임베딩을 수동으로 관리할 수 있습니다.

메시지 세트에 대한 임베딩을 생성합니다. 선택적으로 사용량 핸들러가 있는 `config`를 전달할 수 있으며, 전역적으로 공유되는 `Config`일 수 있습니다.

```ts
import { embedMessages } from "@convex-dev/agent";

const embeddings = await embedMessages(
  ctx,
  { userId, threadId, textEmbeddingModel, ...config },
  [{ role: "user", content: "What is love?" }],
);
```

기존 메시지에 대한 임베딩을 생성하고 저장합니다.

```ts
const embeddings = await supportAgent.generateAndSaveEmbeddings(ctx, {
  messageIds,
});
```

새 모델로 마이그레이션하기 위해 임베딩을 가져오고 업데이트합니다.

```ts
const messages = await ctx.runQuery(components.agent.vector.index.paginate, {
  vectorDimension: 1536,
  targetModel: "gpt-4o-mini",
  cursor: null,
  limit: 10,
});
```

ID로 임베딩을 업데이트합니다.

```ts
const messages = await ctx.runQuery(components.agent.vector.index.updateBatch, {
  vectors: [{ model: "gpt-4o-mini", vector: embedding, id: msg.embeddingId }],
});
```

참고: 차원이 변경되면 이전 것을 삭제하고 새 것을 삽입해야 합니다.

임베딩 삭제

```ts
await ctx.runMutation(components.agent.vector.index.deleteBatch, {
  ids: [embeddingId1, embeddingId2],
});
```

임베딩 삽입

```ts
const ids = await ctx.runMutation(components.agent.vector.index.insertBatch, {
  vectorDimension: 1536,
  vectors: [
    {
      model: "gpt-4o-mini",
      table: "messages",
      userId: "123",
      threadId: "123",
      vector: embedding,
      // 선택 사항, embeddingId로 메시지를 업데이트하려는 경우
      messageId: messageId,
    },
  ],
});
```
